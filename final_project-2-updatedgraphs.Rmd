---
title: "Final Project"
author: "Group 4"
date: "5/27/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include=FALSE}
library(tidyverse)
library(here)
library(readxl)
library(broom)
library(ggridges)
library(olsrr)
library(ggtext)
```

```{r include=FALSE}
schools <- read_xlsx(here::here("US_schools_data.xlsx"))
regionizer <- read_csv(here::here("us census bureau regions and divisions.csv"))
```

# Part 1

## Data Cleaning

```{r}
schools_cleaned <- schools %>%
  select(
    PRIMARY_KEY, TOTAL_EXPENDITURE, INSTRUCTION_EXPENDITURE,
    SUPPORT_SERVICES_EXPENDITURE, OTHER_EXPENDITURE, CAPITAL_OUTLAY_EXPENDITURE,
    ends_with("READING"), ends_with("MATHEMATICS")
  ) %>%
  mutate(
    Year = as.numeric(substr(PRIMARY_KEY, 1, 4)),
    State = substring(PRIMARY_KEY, 6),
    Decade = Year %/% 10 * 10
  )

schools_cleaned <- schools_cleaned %>%
  pivot_longer(
    c(ends_with("READING"),  ends_with("MATHEMATICS")),
    names_to = c("Grade", "Race", "Sex", "Test"),
    names_sep = "_",
    values_to = "Test Score"
  )

regionizer <- regionizer %>%
  mutate(
    State = str_to_lower(State)
  )

schools_cleaned <- schools_cleaned %>%
  mutate(
    State = str_replace_all(str_to_lower(State), "_", " ")
  ) %>%
  left_join(regionizer, by = "State") %>%
  select(-PRIMARY_KEY)

schools_cleaned <- schools_cleaned %>%
  mutate(
    Grade = str_extract(Grade, "[0-9]$"),
    Sex = str_replace(Sex, "A", "all"),
    across(c("State", "Grade", "Race", "Sex", "Test", "Region", "Division"), as.factor)
  )

schools_cleaned <- schools_cleaned %>%
  filter(!is.na(Region))

```

```{r}

# levels(schools_cleaned$Race) <- c("All", 
#                                   "American Indian/Alaskan", 
#                                   "Asian",
#                                   "Black", 
#                                   "Hispanic/Latino", 
#                                   "Hawaiian/Pacific Islander",
#                                   "Two or More Races", 
#                                   "White"
#                                   )
# 
# schools_cleaned$Race <- droplevels(schools_cleaned$Race, exclude = "All")


```


## Data Visualization

First, we have our plot of the relationship between instructional expenditures and testing scores, and how they differ when we factor in region. We have also included plots displaying the relationship with the Sex and Race variables on top of the plot to show how those variables affect Test Score as well.


```{r, fig.width = 10, fig.height = 10}

schools_cleaned %>%
  drop_na(INSTRUCTION_EXPENDITURE, `Test Score`) %>%
  ggplot(mapping = aes(x = INSTRUCTION_EXPENDITURE, y = `Test Score`))+
  geom_smooth(method = "lm", color = "purple", fill = "yellow") +
  facet_wrap(~ Region) +
  theme_bw() +
  theme(text = element_text(family = "mono"),
        axis.text = element_text(size=18),
        axis.title.y = element_text(size=18),
        axis.title.x = element_text(size=18),
        axis.ticks.y=element_blank(),
        plot.title.position = "plot",
        panel.grid = element_blank(),
        legend.position = "none",
        plot.title = element_markdown(lineheight = 1.5, size = 26, family = "mono"),
        panel.border = element_blank(),
        strip.background = element_blank(),
        strip.text = element_text(size=15)) +
  ggtitle("**_Relationship between Intruction Expenditures and Test Scores for each Region_**") +
  xlab("Instruction Expenditures") +
  ylab("Test Scores")
```

Looking at the overall distributions of first set of plots, we can see that the Midwest and the Northeast both are relatively flat, and don't have much alteration in test score based off instruction expenditure. In the South, there is a slight increase in test scores when instruction expenditure is increased, showing a positive correlation betweent those variables. In the South on the other hand, we can see what appears to be a slight decline in the relationship, indicating what could be a negative correlation between expenditures and test scores. This could possible indicate something having to do with other variables in the West, such as maybe school population, or even private versus public school teaching. All in all, it is important to note that none of these plots are very strong by any means, and only imply a slight correlation that might not be included in our final model.

Taking a closer look at the second set of graphs, we can see that for the "all" sex category there is decent increase in test score with an increase in instruction expenditure. Although this distribution isn't the strongest, there is some positive correlation between the two variables when sex is factored in. Analyzing male and female individually, there isn't much difference in their correlations between test scores and expenditures. Overall, the sex variable does not appear to be too indicative of a relationship between expenditures and test scores, but it would be interesting to include in the model.

Lastly, the plots with race overlaid in the relationship between test score and expenditure shows not much at all for a few of the categories such as HP and AM, indicating that we may want to remove these categories from the race variable. It appears that most of these races are flat and don't have much correlation at all, but the categories of TR and AS give some sign of positive correlation, making it an interesting variable to include in our model.

Next, we have te plots that are for the relationship between test score and test type, where we will include the variables of Region, Sex, and Race and how they impact the relationship.

```{r echo=FALSE, fig.width = 10, fig.height = 10}

# region_coloring <- c(
#   Northeast = "#8414eb",
#   South = "#7BAB14",
#   Midwest = "#13D3EC",
#   West = "#EC2C13"
# )

schools_cleaned %>%
  drop_na(`Test Score`, Race) %>%
  mutate(
    Region = fct_relevel(Region, "West", "Midwest", "South", "Northeast"),
    Test = case_when(
      Test == "READING" ~ "Reading Scores",
      TRUE ~ "Math Scores"
    )
  ) %>%
  ggplot(aes(x = `Test Score`, y = Test, fill = Race)) +
  geom_boxplot(width = 0.6,
               position = position_dodge(width = 0.7), alpha = 0.3) +
  geom_jitter(aes(color = Race), alpha = 0.25, position = position_jitterdodge()) +
  labs(title = "**_Reading and Math Test Scores across Regions_**", y = "", x = "") +
  geom_text(aes(x = 140, label = Test, family = "mono", fontface = "bold.italic"),
           stat = "summary",
           size = 6.5,
           nudge_y = 0.5,
           check_overlap = TRUE,
           vjust = "inward",
           hjust="inward") +
  geom_text(aes(x = 160, y = Test, label = Race, color = Race, family = "mono"),
           stat = "summary",
           size = 5,
           position = position_dodge(width = 0.7)) +
  #scale_fill_manual(values = region_coloring) +
  #scale_color_manual(values = region_coloring) +
  scale_x_continuous(breaks = c(180, 220, 260, 300), expand = c(0, 0)) +
  scale_y_discrete(expand = c(0.6, 0)) +
  theme_bw() +
  theme(axis.text = element_text(size=13),
        axis.ticks.y=element_blank(),
        axis.text.y = element_blank(),
        plot.title.position = "plot",
        panel.grid = element_blank(),
        legend.position = "none",
        plot.title = element_markdown(lineheight = 1.5, size = 24, family = "serif"),
        panel.border = element_blank())
```

In these plots, we will be looking at the relationship between test score and the specific test type. We will also overlay the region, sex, and race variables again so that we can analyze how those factor in to the relationship. In the plot for region first, we can see that the median of reading test scores is lower than those for mathematics (about 225 vs. about 250), indicating that the students in this study excel much better in mathematics. When looking how region influences this relationship, the regions don't differ too much from each other, indicating that the median test scores aren't that much different across regions. For the graph with the Sex variable included, we can see that when it comes to the reading test, the males in the study have lower test scores than the females, while for the mathematics test the male and female test scores are not much different from each other. Lastly, looking at the plot including the Race variable, we are able to see large differences among each of the races, regardless of test type. It is indicative by the plot that both the WH and AS races have higher overall test scores than the rest. This can be for a plethora of reasons such as economic status, region, and public vs privte schooling. For this reason, race is definitely a variable that will provide interesting insight to our model.


```{r, fig.width = 10, fig.height = 10}
schools_cleaned %>%
  mutate(
    Decade = (as.numeric(Year) %/% 10) * 10
  ) %>%
  drop_na(`Test Score`) %>%
  ggplot(mapping = aes(y = `Test Score`, x = INSTRUCTION_EXPENDITURE, color=Race)) +
  #geom_jitter(alpha=0.1) +
  geom_smooth(method = "lm", fill = "lightgray") +
  facet_wrap(Region ~ Decade, ncol = 3) +
  theme_bw() +
  theme(text = element_text(family = "mono"),
        axis.text = element_text(size=18),
        axis.title.y = element_text(size=18),
        axis.title.x = element_text(size=18),
        axis.ticks.y=element_blank(),
        plot.title.position = "plot",
        panel.grid = element_blank(),
        legend.position = "none",
        plot.title = element_markdown(lineheight = 1.5, size = 26, family = "mono"),
        panel.border = element_blank(),
        strip.background = element_blank(),
        strip.text = element_text(size=15)) +
  ggtitle("**_Relationship between Intruction Expenditures and Test Scores in each Region Over Time_**") +
  xlab("Instruction Expenditures") +
  ylab("Test Scores")

# NAs for many of the Races for 1990s and 2000s
```

Lastly, we will be plotting the relationship between test scores and expenditures and how that relationship differs over time. Once again we are going to be including the Region, Sex, and Race variables to see how the influence the relationship.

For the first plot with Region, we can see some interesting changes overtime and how it compares across regions. For the Midwest it is interesting to see that there is a negative relationship between the variables in the 90s, and throughout the next two decades it improves to being a flat/slightly positive relationship between the variables. This could have something to do with an improvement in technology and better facilities for learning, which would improve test scores. Not much changes in the Northeast, but we do see changes within the South and the West, where the South starts off in a positive relationship and it increases even more, and the West is like the Midwest where it starts negative and improves to become flat over time. Overall, there are many different factors that could be influencing these changes over time, one being technological advances.


## Linear Regression

Here we went ahead and feet two linear models: one that investigates the relationship between instructional expenditures and mathematics test scores and one that investigates the relationship between instructional expenditures and reading test scores.

```{r}
math_model <- schools_cleaned %>%
  filter(str_to_lower(Test) == "mathematics") %>%
  drop_na(`Test Score`) %>%
  lm(`Test Score` ~ INSTRUCTION_EXPENDITURE, data=.)

reading_model <- schools_cleaned %>%
  filter(str_to_lower(Test) == "reading") %>%
  drop_na(`Test Score`) %>%
  lm(`Test Score` ~ INSTRUCTION_EXPENDITURE, data=.)
```

```{r}
summary(math_model)
summary(reading_model)
```

After running both models, there are a number of different summary statistics that we can look at which will help us in understanding the linear models better. Looking first at the linear model for the mathematics test, we will analyze the Adjusted R-Squared and the p-value for the model. The Adjusted R-Squared for this model is 0.004266 which is not great by any means, and interpreting this it means that 0.4266% of the variation in Test Score can be explained by our model. The p-value for this model is 2.566e-05 which is really small and indicates that our model is statistically significant. With this, we can reject the null hypothesis and conclude that instruction expenditure is an accurate predictor of test score for the Mathematics test.

Now analyzing the reading model, we can see that the Adjusted R-Squared is 0.003594 which is also extremely small and worse than the mathematics model. To interpret this, we would say that 0.3594% of the variation in Test Score can be explained by our model. The p-value for the reading model is still small but larger than the mathematics model at 6.57e-05. We would still conclude that this model is statistically significant and reject the null hypothesis, and conclude that instruction expenditure is an accurate predictor of test score for the Mathematics test.

### Model Comparison

After analyzing both of the models, we are able to see that the mathematics test accounts for a larger proportion of the variability in test score, compared to the reading test. We found Adjusted R-Squared values for the math model and reading model of 0.004266 and 0.003594, respectively. This difference is not that substantial since both of these numbers are quite small, but we do see that the math model has a higher Adjusted R-Squared, indicating that the math test accounts for the larger proportion in Test Score variability.

### Multiple Linear Regression

#### Both Tests
```{r}
schools_cleaned <- within(schools_cleaned, Test <- relevel(Test, ref="MATHEMATICS"))

test_model <- schools_cleaned %>%
  drop_na(`Test Score`) %>%
  lm(`Test Score` ~ INSTRUCTION_EXPENDITURE + Test, data=.)

summary(test_model)
```

After including the new Test variable as an explanatory variable in our model, we can see that this model does account for a larger proportion of variability in Test Score, with an Adjusted R-Squared value of 0.1288, which interpreted means that 12.88% of the variation in Test Score can be explained in our model. This in fact accounts for more variation than the other two models separately.

```{r}
test_model <- schools_cleaned %>%
  drop_na(`Test Score`) %>%
  lm(`Test Score` ~ INSTRUCTION_EXPENDITURE + Test + Year, data=.)

summary(test_model)
```

```{r}
temp <- mutate(drop_na(schools_cleaned, `Test Score`), Scorer = `Test Score`)

model1 <- lm(Scorer ~ INSTRUCTION_EXPENDITURE + Test + Year + Region + Sex + Race  + Grade, data=temp)

# We used these functions for STAT 334 (Applied Linear Models) to do variable selection
# all_sub1 <- ols_step_all_possible(model1)
best.sub1 <- ols_step_best_subset(model1)
```


```{r, fig.width = 10, fig.height = 10}
schools_cleaned %>%
  ggplot(aes(x = `Test Score`, y = Test, fill = Grade)) +
  geom_density_ridges(alpha = 0.5) +
  scale_fill_manual( values = c("steelblue","peachpuff2")) +
  facet_wrap(~ Race) +
  theme_bw() +
  theme(text = element_text(family = "mono"),
        axis.text = element_text(size=18),
        axis.title.y = element_text(size=18),
        axis.title.x = element_text(size=18),
        axis.ticks.y=element_blank(),
        plot.title.position = "plot",
        panel.grid = element_blank(),
        legend.position = "none",
        plot.title = element_markdown(lineheight = 1.5, size = 26, family = "mono"),
        panel.border = element_blank(),
        strip.background = element_blank(),
        strip.text = element_text(size=15)) +
  labs(title =  "**_Test Scores for Grades <span style='color:steelblue;'>Four</span>
and <span style = 'color:peachpuff2;'>Eight</span> based on Race_**") +
  xlab("Test Scores") +
  ylab("")

```


# Part 2

## Visualizing Simulations from the Model

```{r}

schools_lm <- schools_cleaned %>%
  lm(`Test Score` ~ Test + Race + Grade, data = .)

schools_predict <- predict(schools_lm)

schools_sigma <- sigma(schools_lm)

noise <- function(x, mean = 0, sd){
  n <- length(x)
  new_data <- x + rnorm(n, mean, sd)
  return(new_data)
}

schools_new_data <- tibble(predict_score = noise(schools_predict, 
                                          sd = schools_sigma)
                   )

pred <- schools_new_data %>% 
  ggplot(aes(x = predict_score)) +
  geom_histogram(fill = "lemonchiffon3") +
  theme_bw() +
  theme(text = element_text(family = "mono"),
        axis.text = element_text(size=12),
        axis.title.y = element_text(size=12),
        axis.title.x = element_text(size=12),
        axis.ticks.y=element_blank(),
        plot.title.position = "plot",
        panel.grid = element_blank(),
        legend.position = "none",
        plot.title = element_markdown(lineheight = 1.5, size = 26, family = "mono"),
        panel.border = element_blank(),
        strip.background = element_blank(),
        strip.text = element_text(size=12)) +
  xlab("Simulated Test Scores")

obs <- schools_cleaned %>% 
  ggplot(aes(x = `Test Score`)) + 
  geom_histogram(fill = "lemonchiffon3") +
  theme_bw() +
  theme(text = element_text(family = "mono"),
        axis.text = element_text(size=12),
        axis.title.y = element_text(size=12),
        axis.title.x = element_text(size=12),
        axis.ticks.y=element_blank(),
        plot.title.position = "plot",
        panel.grid = element_blank(),
        legend.position = "none",
        plot.title = element_markdown(lineheight = 1.5, size = 26, family = "mono"),
        panel.border = element_blank(),
        strip.background = element_blank(),
        strip.text = element_text(size=12)) +
  xlab("Observed Test Score") 

gridExtra::grid.arrange(pred, obs, nrow = 1, top = "Distribution of Responses")
```
## Generating Multiple Predictive Checks

```{r}
nsims <- 1000

sims <- map_dfc(1:nsims,
                ~tibble(sim = noise(schools_predict, sd = schools_sigma))) 

colnames(sims) <- colnames(sims) %>% 
  str_replace(pattern = "\\.\\.\\.",
                  replace = "_")

sims <- schools_cleaned %>% 
  filter(!is.na(`Test Score`)) %>% 
  select(`Test Score`) %>% 
  bind_cols(sims)

obs_vs_sim <- function(df){
  lm(schools_cleaned$`Test Score` ~ x)
}

sim_r_sq <- sims %>% 
  map( ~lm(`Test Score` ~ .x, data = sims)) %>% 
  map(glance) %>% 
  map_dbl(~.$r.squared)

sim_r_sq <- sim_r_sq[names(sim_r_sq) != "Test Score"]

tibble(sims = sim_r_sq) %>% 
  ggplot(aes(x = sims)) + 
  geom_histogram(binwidth = 0.001, fill = "tomato") +
  theme_bw() +
  theme(text = element_text(family = "mono"),
        axis.text = element_text(size=14),
        axis.title.y = element_text(size=14),
        axis.title.x = element_text(size=14),
        axis.ticks.y=element_blank(),
        plot.title.position = "plot",
        panel.grid = element_blank(),
        legend.position = "none",
        plot.title = element_markdown(lineheight = 1.5, size = 20, family = "mono"),
        panel.border = element_blank()) +
  labs(title = "**Distribution of the _R_^2 Values**") +
  xlab("Simulations") +
  ylab("Count")

 
```


```{r}

test <- schools_cleaned %>%
  lm(`Test Score` ~ Test + Race + Grade, data = .)

summary(test)

```